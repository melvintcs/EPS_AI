{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"USML 4 - DL Basics.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1spxhS0t2Y4","executionInfo":{"status":"ok","timestamp":1632806682889,"user_tz":-480,"elapsed":1063,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"a6f8d596-9374-408e-c2cd-dc6b1055b19e"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Sep 28 05:24:41 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"odhi4kMFnKlG"},"source":["### Basics of PyTorch modeling\n","Here, I will outline the major components of a Deep Learning model."]},{"cell_type":"code","metadata":{"id":"c4lldfqLcmmN"},"source":["import torch\n","import matplotlib.pyplot as plt\n","from torch import nn, optim\n","from torch.utils.data import random_split, DataLoader\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zpEL5jrUtBD5"},"source":["Step 0: Load the dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TNDlggH4d4M","executionInfo":{"status":"ok","timestamp":1632806687771,"user_tz":-480,"elapsed":5,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"faa12988-4a3d-41d3-a282-6ccf846d85f2"},"source":["# Let's download the data first\n","dataset = datasets.MNIST('data', download=True, train=True, transform=transforms.ToTensor())\n","\n","# The dataset is split into X (image) and y (label)\n","# Here we check the first image \n","# (which is an image of 28 by 28 pixels with the label 5)\n","dataset[0]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n","           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n","           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n","           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n","           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n","           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n","           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n","           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n","           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n","           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n","           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n","           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n","           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n","           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n","           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n","           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n","           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n","           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n","           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000],\n","          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n","           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"dASKzeyA4qX2"},"source":["# Separate the image from the label\n","img_batch, label = dataset[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIlPi05z6NOz","executionInfo":{"status":"ok","timestamp":1632806230604,"user_tz":-480,"elapsed":10,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"846c3516-c877-40f7-fe59-c782c0a3d764"},"source":["# .shape is an important method that we use to inspect the\n","# dimensions of a data sample\n","\n","# Here, we have 1 sample with 28 x 28 pixels\n","# The first number indicates batch size.\n","# We usually process a number of samples at a time, so if we\n","# take 32 samples per batch, then each img_batch will have the\n","# shape (32, 28, 28)\n","img_batch.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"hpQKBklL4zw7","executionInfo":{"status":"ok","timestamp":1632791114841,"user_tz":-480,"elapsed":326,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"826bc76f-9d80-43b2-9ac0-63923e6f0a92"},"source":["# Let's print the first image to see what it looks like.\n","# The first image is indexed 0 in the batch.\n","\n","plt.imshow(img_batch[0], cmap='gray')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f80a34dde90>"]},"metadata":{},"execution_count":6},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"A1XoRcGqtDDz"},"source":["# Now let's split the entire dataset into train and validation set\n","train, val = random_split(dataset, [55000, 5000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M16Pb1xV8G2r"},"source":["# Loading data in PyTorch and Tensorflow is done via special classes\n","# DataLoaders makes it easier to work with data across the pipeline\n","train_loader = DataLoader(train, batch_size=32)\n","val_loader = DataLoader(val, batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FmNWaZ1MnaAf"},"source":["### Step 1: Define a model architecture\n","Using sequential means a fully connected neural network where all sucessive nodes are connected to the nodes in the previous layer.\n","\n","Let's try using it to predict images with dimension 28 by 28 using a multi-layer perceptron."]},{"cell_type":"code","metadata":{"id":"sEqBD73MndyS"},"source":["# Note that the tensor separates the image into a matrix that is 28 by 28\n","# For images, each pixel is a feature, therefore, we can represent each image\n","# with 28 x 28 = 784 features.\n","\n","model = nn.Sequential(\n","    nn.Linear(28 * 28, 64),  # (input dimension, output dimension) << input layer\n","    nn.ReLU(),\n","    nn.Linear(64, 64),  # (input dimension, output dimension)  << hidden layer\n","    nn.ReLU(),\n","    nn.Linear(64, 10)  # (input dimension, output dimension) << output layer (10 classes)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FUOm5-8RqWR7"},"source":["What are activation functions? https://mlfromscratch.com/activation-functions-explained/#/"]},{"cell_type":"markdown","metadata":{"id":"zAQSJHcap0kw"},"source":["### Step 2: Define an optimizer"]},{"cell_type":"code","metadata":{"id":"Tm5oOL-0o2c1"},"source":["optimizer = optim.SGD(model.parameters(), lr=1e-2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnKAkd6EqaHO"},"source":["What are optimizers? https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c"]},{"cell_type":"markdown","metadata":{"id":"x2SaGsFYqfha"},"source":["### Step 3: Define loss function"]},{"cell_type":"code","metadata":{"id":"GctW28uIoHQI"},"source":["loss = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UVATqEHtqngW"},"source":["### Step 4: Define training loops"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bwyQ-t6qrSM","executionInfo":{"status":"ok","timestamp":1632797835650,"user_tz":-480,"elapsed":164553,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"6e55a2aa-2428-4674-d417-27b461a70d35"},"source":["num_epochs = 30\n","for epoch in range(num_epochs):\n","    train_losses = list()\n","    train_accuracy = list()\n","    for batch in train_loader:\n","        x, y = batch  # In a dataloader, x is the data and y is the label\n","\n","        # From a dataloader, x is of the shape (batch, channels, dimensions)\n","        # Example (32, 1, 784): Recall that 784 is 28 x 28 which is the image.\n","        # Since we only have 1 channel, we can remove it to make it (32, 784)\n","        b = x.size(0)\n","        x = x.view(b, -1)\n","\n","        # Step 1: Forward the input feature values through the network\n","        logits = model(x)\n","\n","        # Step 2: Compute the objective function\n","        J = loss(logits, y)\n","\n","        # Step 3: Clean any previous accumulated gradients by setting it to 0\n","        model.zero_grad()  # This is like setting params.grad to zero\n","\n","        # Step 4: Accumulate the partial derivatives of J wrt parameters\n","        J.backward()  # This is like summing params.grad with (dJ/dparams)\n","\n","        # Step 5: Apply a step in the opposite direction of the gradient\n","        optimizer.step()  # This is like params = params - learning_rate * params.grad\n","\n","        train_losses.append(J.item())\n","        train_accuracy.append(y.eq(logits.argmax(dim=1)).float().mean())\n","\n","    val_losses = list()\n","    val_accuracy = list()\n","    for batch in val_loader:\n","        x, y = batch  # In a dataloader, x is the data and y is the label\n","\n","        # From a dataloader, x is of the shape (batch, channels, dimensions)\n","        b = x.size(0)\n","        x = x.view(b, -1)\n","\n","        # Forward the input feature values through the network\n","        # ## Since validation don't update weights, we don't need to load the\n","        # ## gradients\n","        with torch.no_grad():\n","            logits = model(x)\n","\n","        # Compute the objective function\n","        J = loss(logits, y)\n","\n","        val_losses.append(J.item())\n","        val_accuracy.append(y.eq(logits.argmax(dim=1)).float().mean())\n","\n","    print(f'Epoch {epoch + 1}, train loss: {torch.tensor(train_losses).mean():.2f}, val loss: {torch.tensor(val_losses).mean():.2f}')\n","    print(f'        train acc: {torch.tensor(train_accuracy).mean():.2f}, val acc: {torch.tensor(val_accuracy).mean():.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, train loss: 1.23, val loss: 0.48\n","        train acc: 0.64, val acc: 0.86\n","Epoch 2, train loss: 0.41, val loss: 0.34\n","        train acc: 0.89, val acc: 0.90\n","Epoch 3, train loss: 0.33, val loss: 0.29\n","        train acc: 0.91, val acc: 0.91\n","Epoch 4, train loss: 0.28, val loss: 0.26\n","        train acc: 0.92, val acc: 0.92\n","Epoch 5, train loss: 0.25, val loss: 0.23\n","        train acc: 0.93, val acc: 0.93\n","Epoch 6, train loss: 0.23, val loss: 0.21\n","        train acc: 0.93, val acc: 0.94\n","Epoch 7, train loss: 0.21, val loss: 0.20\n","        train acc: 0.94, val acc: 0.94\n","Epoch 8, train loss: 0.19, val loss: 0.19\n","        train acc: 0.95, val acc: 0.94\n","Epoch 9, train loss: 0.18, val loss: 0.18\n","        train acc: 0.95, val acc: 0.95\n","Epoch 10, train loss: 0.17, val loss: 0.17\n","        train acc: 0.95, val acc: 0.95\n","Epoch 11, train loss: 0.16, val loss: 0.16\n","        train acc: 0.95, val acc: 0.95\n","Epoch 12, train loss: 0.15, val loss: 0.15\n","        train acc: 0.96, val acc: 0.95\n","Epoch 13, train loss: 0.14, val loss: 0.15\n","        train acc: 0.96, val acc: 0.96\n","Epoch 14, train loss: 0.13, val loss: 0.14\n","        train acc: 0.96, val acc: 0.96\n","Epoch 15, train loss: 0.13, val loss: 0.14\n","        train acc: 0.96, val acc: 0.96\n","Epoch 16, train loss: 0.12, val loss: 0.13\n","        train acc: 0.97, val acc: 0.96\n","Epoch 17, train loss: 0.11, val loss: 0.13\n","        train acc: 0.97, val acc: 0.96\n","Epoch 18, train loss: 0.11, val loss: 0.12\n","        train acc: 0.97, val acc: 0.96\n","Epoch 19, train loss: 0.10, val loss: 0.12\n","        train acc: 0.97, val acc: 0.96\n","Epoch 20, train loss: 0.10, val loss: 0.12\n","        train acc: 0.97, val acc: 0.97\n","Epoch 21, train loss: 0.10, val loss: 0.11\n","        train acc: 0.97, val acc: 0.97\n","Epoch 22, train loss: 0.09, val loss: 0.11\n","        train acc: 0.97, val acc: 0.97\n","Epoch 23, train loss: 0.09, val loss: 0.11\n","        train acc: 0.97, val acc: 0.97\n","Epoch 24, train loss: 0.08, val loss: 0.11\n","        train acc: 0.98, val acc: 0.97\n","Epoch 25, train loss: 0.08, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n","Epoch 26, train loss: 0.08, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n","Epoch 27, train loss: 0.07, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n","Epoch 28, train loss: 0.07, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n","Epoch 29, train loss: 0.07, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n","Epoch 30, train loss: 0.07, val loss: 0.10\n","        train acc: 0.98, val acc: 0.97\n"]}]},{"cell_type":"markdown","metadata":{"id":"EApwRHJ-wbmK"},"source":["As the number of epochs grow, the training and validation accuracy will increase until a point where the validation accuracy will start to fall. This is the point where overfitting happens.\n","\n","If overfitting occurs after an acceptable validation accuracy, then we can simply stop the training at the epoch number right before overfitting happens.\n","\n","What if we have not achieved the acceptable validation accuracy? In this case we need to perform some overfitting techniques. \n","> The most common one is the dropout, which randomly sets some node values to zero.\n",">\n","> This is very similar to bagging ensembles, where each model sees only a subset of values and features.\n",">\n","> In deep learning, each epoch is a small model. Successive epochs adjusts the weights of the previous to get better accuracy. Dropout adds the bagging mechanism to this.\n","\n","In the next section, we will implement the dropout. But let's class the model to make it easier to maintain.\n","> This class is also the default way to construct PyTorch models."]},{"cell_type":"markdown","metadata":{"id":"yz0gi0_OYNsy"},"source":["Because we are switching models, please remember to restart your colab instance!\n","> Go to the menu bar and click Runtime > Restart Runtime.\n",">\n","> Then load all the imports, data, and dataloader codes."]},{"cell_type":"code","metadata":{"id":"WsNGE6GBwbVH"},"source":["class ImageNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.l1 = nn.Linear(28 * 28, 64)\n","        self.l2 = nn.Linear(64, 64)\n","        self.l3 = nn.Linear(64, 10)\n","        self.dropout = nn.Dropout(0.2)\n","    \n","    def forward(self, x):\n","        h1 = nn.functional.relu(self.l1(x))\n","        h2 = nn.functional.relu(self.l2(h1))\n","        dropout = self.dropout(h2)\n","        # dropout = self.dropout(h2 + h1)  # This is known as a residual connection\n","        logits = self.l3(h2)\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HNArS92lXden"},"source":["We are also going to utilize GPU. Always remember:\n","1. The model and data must both reside in the same computational device, i.e. both on CPU or both on GPU.\n","> Data refers to both the X and the y.\n","2. To switch between CPU and GPU, we use the .to() method.\n","> model.to('cuda') or model.to('cpu')\n",">\n","> x.to('cuda') or x.to('cpu')\n",">\n","> y.to('cuda') or y.to('cpu')"]},{"cell_type":"code","metadata":{"id":"YJno5ifAxANU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632806701121,"user_tz":-480,"elapsed":2860,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"3425df49-5d35-4ca3-8355-2f0c79a6a92d"},"source":["# Call the model and load it into the GPU\n","model = ImageNN()\n","model.to('cuda')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ImageNN(\n","  (l1): Linear(in_features=784, out_features=64, bias=True)\n","  (l2): Linear(in_features=64, out_features=64, bias=True)\n","  (l3): Linear(in_features=64, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"f-lZ1DCsxH0f"},"source":["# Define optimizer\n","# Here we use a more efficient optimizer called the Adam, see how fast it\n","# reaches the minimum loss.\n","optimizer = optim.Adam(model.parameters(), lr=1e-2)\n","\n","# Define loss\n","loss = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQLLwu87xWwV","executionInfo":{"status":"ok","timestamp":1632807041168,"user_tz":-480,"elapsed":337066,"user":{"displayName":"Jack Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GheQxBLfOB5r06NZvAvtBxRdMcR_JAM1s8uTB4ts0k=s64","userId":"04426350445905768252"}},"outputId":"0e6390b8-8eda-481a-9ab8-8e48ec248692"},"source":["num_epochs = 30\n","for epoch in range(num_epochs):\n","\n","    train_losses = list()\n","    train_accuracy = list()\n","    model.train()\n","\n","    for batch in train_loader:\n","        x, y = batch  # In a dataloader, x is the data and y is the label\n","\n","        # From a dataloader, x is of the shape (batch, channels, dimensions)\n","        # Example (32, 1, 784): Recall that 784 is 28 x 28 which is the image.\n","        # Since we only have 1 channel, we can remove it to make it (32, 784)\n","        b = x.size(0)\n","        x = x.view(b, -1).to('cuda')\n","        y = y.to('cuda')\n","\n","        # Step 1: Forward the input feature values through the network\n","        logits = model(x)\n","\n","        # Step 2: Compute the objective function\n","        J = loss(logits, y)\n","\n","        # Step 3: Clean any previous accumulated gradients by setting it to 0\n","        model.zero_grad()  # This is like setting params.grad to zero\n","\n","        # Step 4: Accumulate the partial derivatives of J wrt parameters\n","        J.backward()  # This is like summing params.grad with (dJ/dparams)\n","\n","        # Step 5: Apply a step in the opposite direction of the gradient\n","        optimizer.step()  # This is like params = params - learning_rate * params.grad\n","\n","        train_losses.append(J.item())\n","        train_accuracy.append(y.eq(logits.argmax(dim=1)).float().mean())\n","\n","    val_losses = list()\n","    val_accuracy = list()\n","    model.eval()\n","    \n","    for batch in val_loader:\n","        x, y = batch  # In a dataloader, x is the data and y is the label\n","\n","        # From a dataloader, x is of the shape (batch, channels, dimensions)\n","        b = x.size(0)\n","        x = x.view(b, -1).to('cuda')\n","        y = y.to('cuda')\n","\n","        # Forward the input feature values through the network\n","        # ## Since validation don't update weights, we don't need to load the\n","        # ## gradients\n","        with torch.no_grad():\n","            logits = model(x)\n","\n","        # Compute the objective function\n","        J = loss(logits, y)\n","\n","        val_losses.append(J.item())\n","        val_accuracy.append(y.eq(logits.argmax(dim=1)).float().mean())\n","\n","    print(f'Epoch {epoch + 1}, train loss: {torch.tensor(train_losses).mean():.2f}, val loss: {torch.tensor(val_losses).mean():.2f}')\n","    print(f'         train acc: {torch.tensor(train_accuracy).mean():.3f}, val acc: {torch.tensor(val_accuracy).mean():.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, train loss: 0.28, val loss: 0.23\n","         train acc: 0.918, val acc: 0.935\n","Epoch 2, train loss: 0.19, val loss: 0.21\n","         train acc: 0.948, val acc: 0.948\n","Epoch 3, train loss: 0.16, val loss: 0.21\n","         train acc: 0.956, val acc: 0.950\n","Epoch 4, train loss: 0.15, val loss: 0.18\n","         train acc: 0.960, val acc: 0.957\n","Epoch 5, train loss: 0.14, val loss: 0.19\n","         train acc: 0.963, val acc: 0.953\n","Epoch 6, train loss: 0.13, val loss: 0.20\n","         train acc: 0.966, val acc: 0.961\n","Epoch 7, train loss: 0.12, val loss: 0.22\n","         train acc: 0.969, val acc: 0.956\n","Epoch 8, train loss: 0.12, val loss: 0.19\n","         train acc: 0.969, val acc: 0.960\n","Epoch 9, train loss: 0.12, val loss: 0.20\n","         train acc: 0.971, val acc: 0.958\n","Epoch 10, train loss: 0.11, val loss: 0.19\n","         train acc: 0.972, val acc: 0.967\n","Epoch 11, train loss: 0.11, val loss: 0.21\n","         train acc: 0.973, val acc: 0.965\n","Epoch 12, train loss: 0.10, val loss: 0.17\n","         train acc: 0.975, val acc: 0.967\n","Epoch 13, train loss: 0.10, val loss: 0.19\n","         train acc: 0.976, val acc: 0.962\n","Epoch 14, train loss: 0.10, val loss: 0.29\n","         train acc: 0.977, val acc: 0.962\n","Epoch 15, train loss: 0.10, val loss: 0.20\n","         train acc: 0.976, val acc: 0.958\n","Epoch 16, train loss: 0.10, val loss: 0.24\n","         train acc: 0.977, val acc: 0.965\n","Epoch 17, train loss: 0.10, val loss: 0.27\n","         train acc: 0.977, val acc: 0.960\n","Epoch 18, train loss: 0.10, val loss: 0.24\n","         train acc: 0.976, val acc: 0.962\n","Epoch 19, train loss: 0.10, val loss: 0.25\n","         train acc: 0.977, val acc: 0.962\n","Epoch 20, train loss: 0.10, val loss: 0.28\n","         train acc: 0.977, val acc: 0.959\n","Epoch 21, train loss: 0.09, val loss: 0.29\n","         train acc: 0.980, val acc: 0.962\n","Epoch 22, train loss: 0.10, val loss: 0.31\n","         train acc: 0.977, val acc: 0.957\n","Epoch 23, train loss: 0.09, val loss: 0.26\n","         train acc: 0.978, val acc: 0.962\n","Epoch 24, train loss: 0.09, val loss: 0.37\n","         train acc: 0.979, val acc: 0.958\n","Epoch 25, train loss: 0.09, val loss: 0.31\n","         train acc: 0.978, val acc: 0.962\n","Epoch 26, train loss: 0.09, val loss: 0.29\n","         train acc: 0.978, val acc: 0.962\n","Epoch 27, train loss: 0.09, val loss: 0.31\n","         train acc: 0.980, val acc: 0.963\n","Epoch 28, train loss: 0.10, val loss: 0.29\n","         train acc: 0.977, val acc: 0.961\n","Epoch 29, train loss: 0.09, val loss: 0.28\n","         train acc: 0.979, val acc: 0.960\n","Epoch 30, train loss: 0.09, val loss: 0.28\n","         train acc: 0.979, val acc: 0.966\n"]}]}]}